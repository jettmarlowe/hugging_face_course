{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a1069d",
   "metadata": {},
   "source": [
    "# Token Classification\n",
    "* generic task assigns a label to each token in a sentence\n",
    "* this encompasses  \n",
    "    -> named entity recognition (NER)  \n",
    "    -> part of speech tagging (POS)  \n",
    "    -> chunking - finding tokens that belong to the same entity  \n",
    "    -> other things\n",
    "    \n",
    "https://huggingface.co/course/chapter7/2?fw=pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3beac",
   "metadata": {},
   "source": [
    "# Fine-tuning a masked language model\n",
    "* usually you can just use a pretrained model from the HF Hub and fine-tune it directly on your data for the task at hand\n",
    "* If the corpuses are similar, transfer learning will usually produce good results.\n",
    "* Domain adaptation is the process of fine-tuning a pre-trained language model on in-domain data.\n",
    "\n",
    "https://huggingface.co/course/chapter7/3?fw=pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116843a8",
   "metadata": {},
   "source": [
    "# Perplexity (PPL)\n",
    "* This is a common metric used to evaluate language models.\n",
    "* The smaller the value, the better it performs.\n",
    "* Taking the exponent of the Cross-Entropy results gives us the Perplexity.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac05c65",
   "metadata": {},
   "source": [
    "# Translation\n",
    "* A sequence to sequence task, close to summarization\n",
    "\n",
    "https://huggingface.co/course/chapter7/4?fw=pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10525e85",
   "metadata": {},
   "source": [
    "### BLEU metric\n",
    "* Metric for evaluating translation, measures how close the translations are to their labels\n",
    "* It expects the text to already be tokenized so it is hard to compare scores across models that use different tokenizers.\n",
    "* SacreBLUE - now most commonly used metric since it standardizes the tokenization step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c169826",
   "metadata": {},
   "source": [
    "# Summarization\n",
    "* Take a long document and generate a concise summary\n",
    "* mT5 and mBART-50 are multi-lingual text summarization models\n",
    "\n",
    "https://huggingface.co/course/chapter7/5?fw=pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96e1ff8",
   "metadata": {},
   "source": [
    "### ROUGE metric\n",
    "* Recall-Oriented Understudy for Gisting Evaluation\n",
    "* Count the overlapping words but also compute the precision and recall scores for the overlap\n",
    "* Measures how much of the reference summary is captured by the generated one\n",
    "* Common baseline is to just take the 1st three sentences (lead-3 baseline)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40507687",
   "metadata": {},
   "source": [
    "# Question Answering\n",
    "* can do extractive question answering\n",
    "* vs text summarization / synthesis that is needed to answer more open ended questions\n",
    "\n",
    "https://huggingface.co/course/chapter7/7?fw=pt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fad2993",
   "metadata": {},
   "source": [
    "### SQuAD metric\n",
    "* SQuAD v2 is harder and includes questions that don't have an answer\n",
    "* Need data with columns for context, questions, and answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a3f639",
   "metadata": {},
   "source": [
    "# Data Collators\n",
    "* Put together a list of samples into a single training mini-batch\n",
    "* Determine if you need padding or not (are all inputs that same length?)\n",
    "* In situations where you have variable-length labels, you will need inputs and labels that are padded\n",
    "* MLM and CLM are handled by the same data collator, need to set the argument for masked vs causal language modeling\n",
    "\n",
    "\n",
    "https://huggingface.co/course/chapter7/8?fw=pt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
