{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dec70fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformer models are used to solve all kinds of NLP tasks\n",
    "\n",
    "# the pipeline function groups all the preprocessing, model, and postprocessing steps required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4afa04cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jmarlowe/opt/anaconda3/envs/transformers_course/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2a1d42",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da19ac93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9598051905632019},\n",
       " {'label': 'NEGATIVE', 'score': 0.9997242093086243},\n",
       " {'label': 'NEGATIVE', 'score': 0.7810968160629272},\n",
       " {'label': 'POSITIVE', 'score': 0.9995312690734863},\n",
       " {'label': 'POSITIVE', 'score': 0.9976855516433716},\n",
       " {'label': 'POSITIVE', 'score': 0.9872573018074036}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sentiment analysis classifies text as positive or negative.\n",
    "\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "classifier([\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I have the worst cold.\",\n",
    "    \"I like dark clouds\",\n",
    "    \"I love dark clouds\",\n",
    "    \"I like winter\",\n",
    "    \"Winter is coming\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f11a7e",
   "metadata": {},
   "source": [
    "# Zero shot classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b15068c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'This is a course about the Transformers library',\n",
       " 'labels': ['education', 'business', 'politics'],\n",
       " 'scores': [0.8445988893508911, 0.11197422444820404, 0.04342687502503395]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The zero shot classification pipeline lets you select the labels for classification.\n",
    "\n",
    "classifier = pipeline('zero-shot-classification')\n",
    "\n",
    "classifier(\n",
    "    \"This is a course about the Transformers library\",\n",
    "    candidate_labels = [\"education\", \"politics\", \"business\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063978ce",
   "metadata": {},
   "source": [
    "# Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4906f4b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to successfully handle and manage tasks through the use of interactive UI elements such as buttons, lists and widgets. In this course we will understand interactive UI elements using common programming concepts.\\n\\nIn this class,'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Text generation pipeline uses an input prompt to generate text\n",
    "\n",
    "generator = pipeline('text-generation')\n",
    "\n",
    "generator('In this course, we will teach you how to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b703d8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'My cat is small and there is not a lot of room in our house for her to have such a small cat.\" She added that she still had the intention to open the house for cats.\\n\\nThe family say the first move will not only'}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('My cat is small and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a8a848e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'My cat has no teeth, but she can chew on a lot of potatoes this week.\\n\\n\"But this is just my best food, and I\\'m having a lot of fun having all of that at the same time,\" he said. \"'}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('My cat has no teeth, but')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b4136b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Our cat is cute and she also likes to wear boots. She wears them to protect her hands as she\\'s always wearing her best pair. She can do her job when she needs to,\" she said.'}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('Our cat is cute and she also likes to wear boots')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1185449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': \"Yesterday, I had a piece of candy. When I got home from the gym, I looked at the candy. That was on top of my head. It was actually the first candy I'd ever seen it. I got a little bit scared and\"}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator('Yesterday, I had a piece of candy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cdeea1",
   "metadata": {},
   "source": [
    "# Text generation with distilgpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8d7fd6b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'In this course, we will teach you how to get some basic resources for use with a new framework to help you start your own project.'},\n",
       " {'generated_text': 'In this course, we will teach you how to practice it. I\\u200d\\u200d\\u200d is a course of knowledge, instruction and learning in'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = pipeline('text-generation', model='distilgpt2')\n",
    "\n",
    "generator(\n",
    "    'In this course, we will teach you how to',\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ae469e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'My cat is small and needs to learn to be active, as well as enjoy the outdoors. With that said, what this cat feels like when you'},\n",
       " {'generated_text': \"My cat is small and you can't see what has gone wrong if you're trying to see the details of my dog as normal. Her mouth is\"}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\n",
    "    'My cat is small and',\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67434593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Who wants a quarter or a grand. But not all people are like that, because if they were to get back into it, they would surely start'},\n",
       " {'generated_text': \"Who wants a quarter or a half years? Do their kids have any problems? Do they know they're in a situation when you'd get a shot\"}]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator(\n",
    "    'Who wants a quarter or a',\n",
    "    max_length=30,\n",
    "    num_return_sequences=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b47babc",
   "metadata": {},
   "source": [
    "# Fill-mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7c32c66e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 480/480 [00:00<00:00, 187kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 331M/331M [00:04<00:00, 69.2MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 899k/899k [00:00<00:00, 4.68MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 3.50MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1.36M/1.36M [00:00<00:00, 7.51MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'score': 0.1963152289390564,\n",
       "  'token': 30412,\n",
       "  'token_str': ' mathematical',\n",
       "  'sequence': 'This course will teach you all about mathematical models'},\n",
       " {'score': 0.04449247196316719,\n",
       "  'token': 745,\n",
       "  'token_str': ' building',\n",
       "  'sequence': 'This course will teach you all about building models'}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The fill-mask pipeline will predict missing words in a sentence\n",
    "\n",
    "unmasker = pipeline('fill-mask')\n",
    "unmasker('This course will teach you all about <mask> models', top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39632cb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.03633992746472359,\n",
       "  'token': 512,\n",
       "  'token_str': ' car',\n",
       "  'sequence': 'My car moved to the front of the line.'},\n",
       " {'score': 0.03284739330410957,\n",
       "  'token': 1141,\n",
       "  'token_str': ' wife',\n",
       "  'sequence': 'My wife moved to the front of the line.'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker('My <mask> moved to the front of the line.', top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ca0eff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'score': 0.381716251373291,\n",
       "  'token': 8547,\n",
       "  'token_str': ' Irma',\n",
       "  'sequence': 'Hurricane Irma brings high winds and heavy rain.'},\n",
       " {'score': 0.1378900557756424,\n",
       "  'token': 4508,\n",
       "  'token_str': ' Matthew',\n",
       "  'sequence': 'Hurricane Matthew brings high winds and heavy rain.'}]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unmasker('Hurricane <mask> brings high winds and heavy rain.', top_k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715d753",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2721fa48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [00:00<00:00, 387kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1.33G/1.33G [00:22<00:00, 59.5MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 60.0/60.0 [00:00<00:00, 22.9kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 213k/213k [00:00<00:00, 2.11MB/s]\n",
      "/Users/jmarlowe/opt/anaconda3/envs/transformers_course/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'MISC',\n",
       "  'score': 0.9973852,\n",
       "  'word': 'Russians',\n",
       "  'start': 17,\n",
       "  'end': 25},\n",
       " {'entity_group': 'PER',\n",
       "  'score': 0.9991536,\n",
       "  'word': 'Vladimir Putin',\n",
       "  'start': 64,\n",
       "  'end': 78}]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The NER pipeline identifies entities such as persons, organizations, or locations in a sentence\n",
    "\n",
    "ner = pipeline('ner', grouped_entities=True)\n",
    "\n",
    "ner('At least 200,000 Russians have left the country since President Vladimir Putin’s draft began.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "cb7d2418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'PER',\n",
       "  'score': 0.9984539,\n",
       "  'word': 'Ashish Jha',\n",
       "  'start': 54,\n",
       "  'end': 64},\n",
       " {'entity_group': 'LOC',\n",
       "  'score': 0.99894553,\n",
       "  'word': 'White House',\n",
       "  'start': 70,\n",
       "  'end': 81},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.6163364,\n",
       "  'word': 'Covid',\n",
       "  'start': 84,\n",
       "  'end': 89},\n",
       " {'entity_group': 'ORG',\n",
       "  'score': 0.9986109,\n",
       "  'word': 'The Washington Post',\n",
       "  'start': 108,\n",
       "  'end': 127}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ner(\"You’re doing it for your family and your friends, Dr. Ashish Jha, \\\n",
    "the White House’s Covid coordinator, told The Washington Post.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a6a3f",
   "metadata": {},
   "source": [
    "# Question Answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e61ba5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 473/473 [00:00<00:00, 179kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 261M/261M [00:04<00:00, 65.2MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 29.0/29.0 [00:00<00:00, 10.9kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 213k/213k [00:00<00:00, 2.90MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 436k/436k [00:00<00:00, 4.00MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'score': 0.3739520013332367,\n",
       " 'start': 16,\n",
       " 'end': 48,\n",
       " 'answer': 'for your family and your friends'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer = pipeline('question-answering')\n",
    "\n",
    "question_answerer(\n",
    "    question='Why are we doing this?',\n",
    "    context='You’re doing it for your family and your friends, Dr. Ashish Jha, \\\n",
    "the White House’s Covid coordinator, told The Washington Post.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c8c572da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.15458625555038452,\n",
       " 'start': 52,\n",
       " 'end': 73,\n",
       " 'answer': 'take a falconry class'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question='What should I do next?',\n",
    "    context='Today I need to climb a volcano, hug a redwood, and take a falconry class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f33c1dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.2575291693210602,\n",
       " 'start': 16,\n",
       " 'end': 31,\n",
       " 'answer': 'climb a volcano'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question='What should I do first?',\n",
    "    context='Today I need to climb a volcano, hug a redwood, and take a falconry class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7467f333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.0881502777338028,\n",
       " 'start': 33,\n",
       " 'end': 46,\n",
       " 'answer': 'hug a redwood'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question='Who are you?',\n",
    "    context='Today I need to climb a volcano, hug a redwood, and take a falconry class.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bd923247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 0.06383596360683441,\n",
       " 'start': 59,\n",
       " 'end': 73,\n",
       " 'answer': 'falconry class'}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_answerer(\n",
    "    question='Who am I?',\n",
    "    context='Today I need to climb a volcano, hug a redwood, and take a falconry class.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e6116",
   "metadata": {},
   "source": [
    "# Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6153fe51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1.80k/1.80k [00:00<00:00, 675kB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1.22G/1.22G [00:19<00:00, 64.1MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 26.0/26.0 [00:00<00:00, 9.74kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 899k/899k [00:00<00:00, 4.77MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 456k/456k [00:00<00:00, 2.62MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Rates of severe Covid are already so low among this group that booster shots don’t seem to have a huge health benefit . Some people are fearful of  eedles or prefer to avoid taking unnecessary medicines . Others were sick for a day or two after getting an earlier Covid shot and would prefer not to repeat the experience .'}]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer = pipeline('summarization')\n",
    "\n",
    "summarizer('Whether to get a booster shot is a closer call for healthy people under 50, \\\n",
    "            many experts believe. Rates of severe Covid are already so low among this group \\\n",
    "            that booster shots don’t seem to have a huge health benefit. Of course, the downsides \\\n",
    "            of the shots also seem to be small, because research has consistently shown them to be safe. \\\n",
    "            But getting a booster shot is not wholly without downsides. Some people are fearful of \\\n",
    "            needles or prefer to avoid taking unnecessary medicines. Other people were sick for a day \\\n",
    "            or two after getting an earlier Covid shot and would prefer not to repeat the experience. \\\n",
    "            For hourly workers and single parents, a day in bed can also bring financial or logistical burdens,\\\n",
    "            especially in a country without guaranteed sick leave or child care.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "75813f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' Ben Weintraub dropped out of college to pursue a career in cryptocurrencies . In April, a hacker exploited a flaw in Beanstalk’s design to steal more than $180 million from users . This year, $2.2 billion in cryptocurrency has been stolen from DeFi projects .'}]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarizer('Not long after dropping out of college to pursue a career in cryptocurrencies, Ben Weintraub woke up to some bad news.Mr. Weintraub and two classmates from the University of Chicago had spent the past few months working on a software platform called Beanstalk, which offered a stablecoin, a type of cryptocurrency with a fixed value of $1. To their surprise, Beanstalk became an overnight sensation, attracting crypto speculators who viewed it as an exciting contribution to the experimental field of decentralized finance, or DeFi. \\\n",
    "Then it collapsed. In April, a hacker exploited a flaw in Beanstalk’s design to steal more than $180 million from users, one of a series of thefts this year targeting DeFi ventures. The morning of the hack, Mr. Weintraub, 24, was home for Passover in Montclair, N.J. He walked into his parents’ bedroom. \\\n",
    "“Wake up,” he said. “Beanstalk is dead.” \\\n",
    "Hackers have terrorized the crypto industry for years, stealing Bitcoin from online wallets and raiding the exchanges where investors buy and sell digital currencies. But the rapid proliferation of DeFi start-ups like Beanstalk has given rise to a new type of threat.\\\n",
    "These loosely regulated ventures allow people to borrow, lend and conduct other transactions without banks or brokers, relying instead on a system governed by code. Using DeFi software, investors can take out loans without revealing their identities or even undergoing a credit check. As the market surged last year, the emerging sector was hailed as the future of finance, a democratic alternative to Wall Street that would give amateur traders access to more capital. Crypto users entrusted roughly $100 billion in virtual currency to hundreds of DeFi projects.\\\n",
    "But some of the software was built on faulty code. This year, $2.2 billion in cryptocurrency has been stolen from DeFi projects, according to the crypto tracking firm Chainalysis, putting the overall industry on pace for its worst year of hacking losses.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be1d1d9",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0a23b4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 1.42k/1.42k [00:00<00:00, 543kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 301M/301M [00:05<00:00, 59.0MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 42.0/42.0 [00:00<00:00, 13.9kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 802k/802k [00:00<00:00, 4.68MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 778k/778k [00:00<00:00, 4.07MB/s]\n",
      "Downloading: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 1.34M/1.34M [00:00<00:00, 6.25MB/s]\n",
      "/Users/jmarlowe/opt/anaconda3/envs/transformers_course/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'translation_text': 'This course is produced by Hugging Face.'}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The translator provides translation from one language to another.\n",
    "\n",
    "translator = pipeline('translation', model='Helsinki-NLP/opus-mt-fr-en')\n",
    "translator('Ce cours est produit par Hugging Face.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc5adb",
   "metadata": {},
   "source": [
    "# Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac2bdaf",
   "metadata": {},
   "source": [
    "There are three main categories of transformer models\n",
    "* GPT-like (auto-regressive)\n",
    "* BERT-like (auto-encoding)\n",
    "* BART/T5-like (sequence-to-sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ec7a3e",
   "metadata": {},
   "source": [
    "These are all language models that have been trained on tons of text data.  \n",
    "They are self-supervised (humans are not needed to label the data). The labels are created automatically from the inputs.  \n",
    "Better performance is achieved by increasing the model size, but that has a COST (time, compute resources, and carbon).  \n",
    "* Choose a low carbon compute center\n",
    "* Use pretrained model\n",
    "* Fine-tune a model instead of training from scratch\n",
    "* Start smaller and debug as you go\n",
    "* Do a lit review to choose hyperparameter\n",
    "* Do a random search instead of a grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e548c8dd",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bf1b5d",
   "metadata": {},
   "source": [
    "#### Pretraining"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95bee6c",
   "metadata": {},
   "source": [
    "Pre-training - training a model from scratch.  \n",
    "Weights are randomly initialized.  \n",
    "Training starts without any prior knowledge.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be44f6e4",
   "metadata": {},
   "source": [
    "#### Fine-tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6efbfd",
   "metadata": {},
   "source": [
    "Acquire a pretrained language model, then perform additional training with a dataset specific to your task "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ab9bb",
   "metadata": {},
   "source": [
    "#### Transfer learning \n",
    "Initializing a model with another model's weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedde5fc",
   "metadata": {},
   "source": [
    "GPT2 was pretrained on 40GB of internet text posted by users on Reddit.  \n",
    "BERT was pretrained on the content of the English wikipedia and 11,000 unpublished books.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf1e07f8",
   "metadata": {},
   "source": [
    "Transfer learning is applied by dropping the head of the pretrained model while keeping its body.  \n",
    "The pretrained model should be as similar as possible to the task it needs to be fine tuned on.  \n",
    "The pretrained model transfers its knowledge but also any bias it contains. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e949556",
   "metadata": {},
   "source": [
    "# Transformer Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf79eb4",
   "metadata": {},
   "source": [
    "The transformer is based on the attention mechanism.  \n",
    "The transformer architecture has two pieces: an encoder and a decoder.\n",
    "\n",
    "Inputs: The encoder encodes text into numerical representations, creating embeddings or features.\n",
    "These are fed into the decoder.  \n",
    "The decoder decodes the representations from the encoder.  \n",
    "It produces output probabilities.  \n",
    "  \n",
    "Attention layers tell the model to pay attention to specific words in the sentence you provide to it.  \n",
    "A word has meaning but it is deeply affected by the context in which it appears.  \n",
    "The attention mask can be used to prevent the model from paying attention to special words.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf005547",
   "metadata": {},
   "source": [
    "**Architecture** - skeleton of the model, the definition of each layer and each operation that happen within the model.  \n",
    "**Checkpoints** - weights that will be loaded in a given architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f49f5c0",
   "metadata": {},
   "source": [
    "## Encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16a2b3c",
   "metadata": {},
   "source": [
    "The encoder outputs a numerical representation for each word used as input.  \n",
    "Outputs a feature vector (or feature tensor) for each word of the initial sequence.  \n",
    "Each word in the initial sequence affects *every* word's representation.  \n",
    "The vector holds the meaning of the word within the text.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e4c56",
   "metadata": {},
   "source": [
    "##### When to use?\n",
    "* bi-directional - context from the left and the right\n",
    "* good at extracting meaningful information\n",
    "* they are very good at: sequence classification, question answering, masked language modeling, sentiment analysis, named entity recognition, extractive question\n",
    "* natural language understanding\n",
    "* BERT, RoBERTa, ALBERT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4b583c",
   "metadata": {},
   "source": [
    "## Decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad273dcf",
   "metadata": {},
   "source": [
    "The decoder creates a feature tensor from initial sequence.  \n",
    "The decoder outputs numerical representation.  \n",
    "The self-attention mechanism is different from an encoder.  \n",
    "It is using masked self-attention. It hides the values of context on the right.  \n",
    "Words can only see words on their left side. The right side is hidden.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4625f",
   "metadata": {},
   "source": [
    "##### When to use?\n",
    "* uni-directional - access to their left OR right context\n",
    "* great at causal tasks and generating sequences, guessing the next word in a sentence, text generation\n",
    "* NLG - natural language generation \n",
    "* GPT-2, GPT Neo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e3679",
   "metadata": {},
   "source": [
    "## Sequence-to-sequence models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56b3e8f",
   "metadata": {},
   "source": [
    "Encoder-decoder use both parts.  \n",
    "The encoder outputs are used an input for the decoder. We also give the decoder the start of a sequence word.  \n",
    "Using this representation and a prompt as input, the decoder generates a word.  \n",
    "Throw away the encoder part.  \n",
    "The word it has just output can now be used as an input to the decoder.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f7fe5b",
   "metadata": {},
   "source": [
    "The encoder takes care of understanding the sequence and extracting the context into a vector.  \n",
    "The decoder takes carer of generating a sequence according to the understanding of the encoder.   \n",
    "Output length is independent of input length in the encoder-decoder model.  \n",
    "They also handle variable output lengths.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca13604",
   "metadata": {},
   "source": [
    "##### When to use?\n",
    "* many-to-many, translation, summarization, generative question answering\n",
    "* weights are not necessarily shared across the encoder and decoder\n",
    "* input distribution is different from output distribution\n",
    "* BART, T5, Pegasus, ProphetNet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5174facf",
   "metadata": {},
   "source": [
    "# Beware of Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ab55e",
   "metadata": {},
   "source": [
    "#### The models aren't neutral. \n",
    "#### Depending upon the input data, the model could very easily generate sexist, racist, or homophobic content\n",
    "#### You can't fine tune this away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d1b24a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 570/570 [00:00<00:00, 216kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 440M/440M [00:10<00:00, 40.8MB/s]\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 28.0/28.0 [00:00<00:00, 8.96kB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 232k/232k [00:00<00:00, 1.74MB/s]\n",
      "Downloading: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 466k/466k [00:00<00:00, 3.29MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carpenter', 'lawyer', 'farmer', 'businessman', 'doctor']\n",
      "['nurse', 'maid', 'teacher', 'waitress', 'prostitute']\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "unmasker = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
    "result = unmasker(\"This man works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])\n",
    "\n",
    "result = unmasker(\"This woman works as a [MASK].\")\n",
    "print([r[\"token_str\"] for r in result])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
